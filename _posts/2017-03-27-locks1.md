---
title: '浅谈进程同步解决方案（1）：自旋锁'
date: 2017-03-27
---

进程同步问题是操作系统面临的核心问题之一，如经典的生产者消费者问题、读者写者问题等。目前已经有诸如自旋锁、信号量、管程等一系列解决方案。实际上，在信号量等技术提出之前，还有很多更加古老甚至蹩脚的解决方案。《浅谈进程同步解决方案》系列博客中，我们就聊一聊针对进程同步问题，人们提出的一些解决办法及其演化过程。

本系列的第一篇博客，我们先从进程同步问题讲起，
从原始的锁变量解决方案，引出现代操作系统中最常用的自旋锁机制。


## 进程同步

计算机科学中的同步（Synchronization）有两种含义：即进程同步和数据同步。
按照Wiki Pedia对[synchronization词条](https://en.wikipedia.org/wiki/Synchronization_(computer_science))给出的释义，
数据同步与进程同步没有直接的关系，诸如存储技术中的数据一致性等问题
才属于数据同步的范畴。

本文关注的重点是进程同步。究竟何为进程同步呢？
简单来说，进程同步就是让多个进程能够按照约定的先后次序执行，
从而获得预期的、正确的程序运行结果。

我们知道，在多任务操作系统中，可以同时运行多个进程（或者线程）。
有时候，我们需要多个进程或线程协作完成一件事情，
而这种协作能够成功可能就依赖于正确的执行顺序。
例如，一个web服务器程序可能需要为每个socket连接创建一个工作线程，
如果socket连接结束了，服务器主线程需要及时回收工作线程的资源。
显然，主线程不能提前回收资源，否则就破坏了工作线程的执行；
但如果回收过晚甚至不回收，就造成了资源浪费、内存泄漏等问题。
可见，web服务器程序存在这样一种顺序约束：
```
主线程：  创建工作线程->                             -> 回收资源
工作线程：              工作线程执行 -> 工作线程结束
```

为了实现这样的顺序要求，就需要工作线程在结束的时候能够“告诉”主线程，
或者说主线程能够监听工作线程的结束行为。
这就是进程同步要做的事情：为程序提供提供同步机制，允许程序对其执行顺序
施行自我控制。

### 数据竞争

我们已经知道了进程同步的基本含义，即对进程的执行顺序进行控制。
在现实中，如果不能正确地进行进程同步，会带来各种各样的问题。
像上文说的web服务器主线程何时回收资源只是一种情况，
还有更多更隐蔽、难以发现的同步错误（synchronization error）
困扰着经验不足的新手程序员们，
主要就是数据竞争（data race）。
数据竞争常发生在有共享数据的任务之间，
尤其是在多线程并发编程中常会出现。

考虑这样的一段程序：主线程创建两个子线程A和B，分别对某个全局变量
执行加1和减1，代码如下：
```
// 全局变量
a = 100

// 线程A的入口函数
funcA:
  a ++

// 线程B的入口函数
funcB:
  a --

// 主函数
main:
  create_thread(funcA)
  create_thread(funcB)
  print a
```

理想的输出结果应该是100，因为A和B的操作互相抵消了。
但实际上，假设不对A和B采取任何同步手段，在操作系统的调度的作用下，
真实的输出结果可能是99或者101。
这是因为`a ++`和`a --`这两段代码在编译为机器码后，
有可能会以这样的顺序执行：

```
funcA: load a -> reg += 1 -->                   -> store a
funcB:                        load a -> regB -=1          -> store a

value of a:                                               101       99
```

可见，以上述顺序执行的结果就是a的值最终变成了99。
出现这种情况的根源在于：funcA还没有来得及把寄存器中的101放回内存中a的位置，
funcB就开始执行了，结果funcB取到的是“旧”的的值，即100。
这样，最终a的值就取决于谁最后把寄存器的值放回内存，
最后放回内存的值将会覆盖更早的结果。

类似这样，因为指令执行顺序的不可预测性而导致的错误的情况
还有很多，
读者可以参照[CSAPP 2ed](http://csapp.cs.cmu.edu/)的12.5节的代码自行编程运行书中提供的例子，体会因为数据竞争带来的灾难性的错误结果。

此外，即使假设你的每一个C语言语句都是原子的，
也会有数据竞争的情况出现。
[Modern Operating Systems 4ed](https://www.amazon.com/Modern-Operating-Systems-Andrew-Tanenbaum/dp/013359162X/ref=sr_1_1?ie=UTF8&qid=1487074667&sr=8-1&keywords=modern+operating+systems 'Modern Operating Systems')的2.3.1就给出了一个关于
SPOOLING的例子的数据竞争的例子，
感兴趣的读者可以自行阅读。

### 临界区

解决数据竞争问题的最基本的办法就是设立临界区（critical region）。
所有可能导致数据竞争的代码段都应属于临界区，
主要就是对共享数据的读写操作。
我们可以通过这样几个原则，利用临界区来解决数据竞争问题：
（摘自[Modern Operating Systems 4ed](https://www.amazon.com/Modern-Operating-Systems-Andrew-Tanenbaum/dp/013359162X/ref=sr_1_1?ie=UTF8&qid=1487074667&sr=8-1&keywords=modern+operating+systems 'Modern Operating Systems')）

- 两个进程不能同时处于它们的临界区中。
- 不能对CPU的数量或者速度作出假设。
- 在临界区外的进程不能阻塞其他任何进程
- 进程不能为了进入临界区永远等待下去

以上几项原则建立的抽象的临界区模型可以完美地解决数据竞争问题。
接下来的问题，就是如何实现上述的临界区模型，实践证明，这并不是一件容易的事情。

## 从锁变量到自旋锁

在操作系统介入之前，所有的临界区互斥操作都是基于busy waiting的原理实现的。
Busy waiting的思想是：当有进程占据临时区时，其他进程在临界区入口处循环等待，即所谓的盲等，
直到临界区空出来，才跳出循环进入临界区。
显然，盲等的进程会因为无意义的循环浪费一部分CPU时间，
但这确实是简单有效的解决方案。
举个栗子，如果你正急着蹲坑，却发现坑位满着，这时候你是在厕所等着，还是回去过一会再来呢？显然大多数人的选择应该是原地等待。

当然，我们很容易能发现，盲等的方法适合的场景就像等坑位一样，适合比较着急、而预期的等待时间又不会太长的情景。如果你并不着急，或者可能要等很久，那你可能会考虑先休息一会，或者做点别的事情。这样的情景不适合用盲等思路来解决，我们将在下一篇博客中讨论这样的情况。

## 从锁变量到自旋锁

在操作系统介入之前，所有的临界区互斥操作都是基于busy waiting的原理实现的。
Busy waiting的思想是：当有进程在临时区时，进程进入一个循环，
直到临界区空出来，才跳出循环进入临界区。

### 失败的方案：用一个锁变量实现临界区

根据busy waiting的思想，人们很容易想到，使用一个整形（或者布尔）变量
来表示临界区的状态。假设这个变量为`int lock`，我们可以规定：当`lock`为0时，
代表临界区可以进入；当`lock`为1时，代表临界区不可进入。
任何进程在进入临界区之前先检测`lock`的值，
如果为0则进入临界区，并设置其值为1，离开临界区时，再设置其值为0。

看起来很美好，但实际这种做法是错误的。
在我们试图用`lock`保护其他共享变量的同时，我们实际上引入了
一个新的共享变量，那就是`lock`本身。
考虑这样的情景：
- 初始状态：临界区内没有进程，`lock`的值为0
- 进程A读取`lock`的值，判断是0，于是继续执行，然而在A执行写操作的指令之前，操作系统决定执行B进程
- 进程也读取`lock`的值，发现也是0（进程A还没有对`lock`发起写操作），于是B对`lock`写入1，进入临界区。B在临界区内时，操作系统又突然调度了进程A。
- 进程A并不知道刚才发生了什么，它还认为`lock`是0，并继续写入`lock`为1，然后也进入了临界区。

显然，在上述的情景中，A和B两个进程同时进入了临界区，`lock`并没有起到互斥的作用。

虽然使用一个变量的例子进行互斥的方法失败了，但并不意味着这不是一个好的思路。
实际上，稍加分析我们就能发现，
这样方法失败的根本原因在于：进程对`lock`变量的读和写是两个分解动作，不是原子的，
可以被操作系统中断，从而导致上述情况的发生。
实际上，我们只需要稍加改变，就能实现正确的锁变量。

### 锁变量的改进版本：用TSL指令进行读写

为了让用户程序实现对`lock`的原子的读写操作，
硬件开始专门提供了一个特殊的指令：`TSL`，即test and lock，
它有两个参数，形如`TSL R0 LOCK`，其中`R0`表示寄存器，
`LOCK`表示锁变量在内存中的地址。
这条指令所进行的动作序列是这样的：

- 把内存地址为`LOCK`处的值读到寄存器`R0`中
- 向`LOCK`地址的内存单元写入1

实际上，`TSL`就是读指令和写指令的一个组合。
它的特殊在于，`TSL`指令的执行是原子的，即不能被中断打断。
实现这样的原子操作需要特殊的硬件支持，一般来说可以通过
锁住总线（阻止中断产生和其他CPU对内存的访问）来实现。

有了`TSL`指令，我们就可以实现正确的锁变量临界区：
```
enter_region:
	TSL R0, LOCK
	CMP R0, 0
	JNE enter_region
	RET

leave_region:
	MOVE LOCK 0
	RET
```

进程在进入临时区时调用`enter_region`，在离开时调用`leave_region`，
就能够保证临界区的互斥性。
这时你可能会想：虽然`TSL R0, LOCK`这条指令不能被中断，
那万一在它和`CMP R0, #0`之间发生了进程切换，会不会导致错误发生呢。
实际上，无论这次上锁是否成功，都不会发生问题，我们简要分析一下：

情况1：A进入临界区之前，`lock`为0，A的`TSL`将对`lock`上锁，修改其值为1。如果在`CMP`指令之前有其他进程尝试`TSL`上锁，它们的操作将会覆盖`lock`，但只有A的`R0`寄存器得到了`lock`的0值的副本，只有A能够从`enter_region`返回，其他进程将进入循环，重复上述操作。

情况2：A进入临界区之前，`lock`已经为1，A上锁后得到了`lock`为1的副本。如果在`CMP`执行之前A是否被切走，A未来都会重新跳回到`enter_region`的入口。如果在A被切走后，占有临界区的进程释放了临界区，A则不能立即进入，需要在下一个循环中重新尝试加锁。

通过上述的简要分析，不难发现，这短短的几行指令确实实现了一个真实可用的互斥机制。
然而，这还不是完美的解决方案，尤其是考虑到真实系统中除了用户进程，
还有中断处理程序。

我们考虑这样一个情况：当一个A进程占据了`lock`的时候，系统发生了中断，碰巧中断处理程序也需要占据`lock`而进入临界区，这就发生了死锁：因为操作系统不能调度中断处理程序，只能等待结束并返回。这样系统就进入了死锁状态，谁也不能继续执行。

解决这个问题的办法在上锁之后关闭本地CPU的中断，阻止拥有锁的进程A在临界区内被中断打断。这样就解决了中断处理程序带来的死锁问题。然而这又产生了新的问题：如果进程A在临界区内执行了某个操作导致自己被阻塞（比如进行一次磁盘IO，由于磁盘速度很慢，所以操作系统会把进程A挂起，转而执行其他进程）从而导致发生进程抢占，进程B开始执行，将带来严重的错误。因为中断已经被关闭，操作系统的调度器所依赖的时钟中断不能触发，除非进程B通过某些系统调用让出CPU，A将永远不能运行。A只要不运行，就不能释放锁，也不能打开中断，时间一长，必然导致死锁或者大量中断得不到响应，从而出现严重问题。

为了解决上述问题，只能在锁的持有期间关闭进程抢占，也就是只能让拥有锁的A进程执行，操作系统调度器要无条件保证A的执行，直到抢占被打开。

我们发现最初的一个简单的锁变量，现在需要进行如下的改进：
- 在锁持有期间，要关闭本地CPU的中断。
- 在锁持有期间，要关闭进程抢占。

实际上，拥有以上两种特性的锁变量就是现在常用的spinlock，即自旋锁。

### 锁变量的进一步改良：自旋锁

自旋锁（spinlock）实际上就是上一节简单的锁变量的一个改良，
自旋锁的争用函数（即`enter_region`）本质上还是一个无限循环，
只不过增加了在持有锁后禁止抢占和禁止中断的代码。

一个典型的自旋锁的实现是这样的：
```
// 自旋锁入口函数伪代码
trylock(LOCK) {
	while(true) {
      preempt_disable()     // 禁止抢占
      local_irq_disable()   // 禁止本地CPU中断

      TSL R0, LOCK
      if (R0 == 0) break

      local_irq_enable()     // 打开本地中断
      preempt_enable()       // 打开抢占

      // 不断读LOCK的值，如果为1则继续循环，为0则再次尝试加锁
      while(!canlock(LOCK)) {}
	}
	return
}

// 自旋锁出口函数伪代码
unlock(LOCK) {
	MOV LOCK, 0
	local_irq_enable()     // 打开本地中断
	preempt_enable()       // 打开抢占
	return
}
```

在入口函数中，为什么要在争用失败之后重新打开中断和抢占呢？
因为争用失败后，进程可能要在一段时间内开始死循环，
此时进程并不在临界区中，关闭抢占和中断都没有任何意义，因此
需要把它们打开，允许其他进程与当前进程一起竞争CPU。

此外，在出口函数中，需要先设置`LOCK`的值，才能打开中断和抢占。
否则，如果先打开了中断，一旦中断立即发生，并争用当前这个自旋锁，
由于`LOCK`此时还是1，将会导致上一节讨论的死锁情况发生。
此外，抢占必须在中断打开之后打开，否则将会出现上一节讨论的
调度器无法运作的情况。

### 不关中断的自旋锁

上一节我们讨论的自旋锁，需要进程在持有锁期间关闭抢占和中断。
实际上，如果是在中断处理程序中使用自旋锁，则完全没有必要
关闭中断，因为中断处理程序的执行环境本身就不允许中断发生。
因此，一般操作系统都会提供两套自旋锁接口，一套关闭中断，
另一套不关闭。

除了中断处理程序可以放心地使用开中断的自旋锁之外，
如果你确定你的自旋锁不可能被任何一个中断处理程序争用，
那么你也可以大胆地使用无锁版本的自旋锁。

读到这里，读者可能想到这样一个问题：既然不需要关中断，那么是不是可以允许在
自旋锁期间发生抢占呢？毕竟在中断打开情况下，发生抢占后
持有锁的进程也不会被永远剥夺运行的机会。

实际上，在自旋锁持有期间关闭抢占和关中断的关系，就像是鸡和蛋的关系，
很难说是谁导致了谁，除了笔者在上文中提到的为了防止中断造成死锁而
关中断，进一步必须关闭抢占这种说法之外，还可以有另一种说法，那就是
由于自旋锁的争用采用的是“盲等”的方式，就好比一个人站着厕所坑位，其他人又着急用，
因此在厕所门口“在线等”。如果占据着锁的进程允许被抢占，
则实际上拖长了锁的占有时间，其他“盲等”的进程等待时间更长。
显然这种“占着茅坑不拉屎”的行为是不受欢迎的。
从这个角度来说，关抢占的初衷更像是为了提高自旋锁的效率，从而
提升整个系统的资源利用率，并不是完全为了关中断这个目标服务的。

### 单核系统中的自旋锁

前面讨论的自旋锁都是针对多核的情况，默认多个进程可以真正地
并行执行。我们不妨考虑一下，在早期的单核CPU上，
是否需要自旋锁，自旋锁又应该如何来设计呢。

回忆一下，自旋锁持有期间需要关闭抢占，
如果为了防止中断发生造成死锁，还需要关闭中断。
而在单核CPU上，如果抢占被关闭了，那可以肯定没有任何第二个
进程能够与你争夺CPU使用权。
因此，单核CPU的自旋锁实现就是关闭抢占，而不需要做任何事情
（关中断版本的自旋锁还需要关闭中断）。

## Linux的自旋锁实现

通过上述讨论，我们基本掌握了自旋锁的工作、实现的原理和方法。
下面我们来看看在具体的Linux内核，自旋锁是如何被实现的。

Linux也提供了两个版本的自旋锁争用函数，即关中断版本和不关中断版本。
不关中断版本的代码如下（来自`kernel/locking/spinlock.c`）
```
#define BUILD_LOCK_OPS(op, locktype)                                    \
void __lockfunc __raw_##op##_lock(locktype##_t *lock)                   \
{                                                                       \
        for (;;) {                                                      \
                preempt_disable();                                      \
                if (likely(do_raw_##op##_trylock(lock)))                \
                        break;                                          \
                preempt_enable();                                       \
                                                                        \
                if (!(lock)->break_lock)                                \
                        (lock)->break_lock = 1;                         \
                while (!raw_##op##_can_lock(lock) && (lock)->break_lock)\
                        arch_##op##_relax(&lock->raw_lock);             \
        }                                                               \
        (lock)->break_lock = 0;                                         \
}
```

这段代码跟我们上面自己写的伪代码有几处不同。
首先，使用了一个`break_lock`变量，这个变量的作用是告诉自旋锁的持有者，
有人正在争用你的锁，希望你尽快离开临界区。
如果锁的持有进程愿意的话，它可能会选择更快的执行路径从而释放自旋锁。

其次，`arch_##op##_relax(&lock->raw_lock)`是体系结构相关的放松函数（relax function），这个函数会执行一些空操作指令（例如x86上的nop指令）的一些变体，这些指令
可以在较低的电耗下运行，从而降低CPU的电量开销。

此外，对于需要关中断的版本，我们只需要在相应的位置加入关中断的操作函数即可，相应的代码如下（来自`kernel/locking/spinlock.c`）：
```
unsigned long __lockfunc __raw_##op##_lock_irqsave(locktype##_t *lock)  \
{                                                                       \
        unsigned long flags;                                            \
                                                                        \
        for (;;) {                                                      \
                preempt_disable();                                      \
                local_irq_save(flags);                                  \
                if (likely(do_raw_##op##_trylock(lock)))                \
                        break;                                          \
                local_irq_restore(flags);                               \
                preempt_enable();                                       \
                                                                        \
                if (!(lock)->break_lock)                                \
                        (lock)->break_lock = 1;                         \
                while (!raw_##op##_can_lock(lock) && (lock)->break_lock)\
                        arch_##op##_relax(&lock->raw_lock);             \
        }                                                               \
        (lock)->break_lock = 0;                                         \
        return flags;                                                   \
}
```

## 总结

- 我们讨论了进程同步问题，并描述了一种典型的由于进程同步不正确而导致的同步错误：数据竞争。
- 为了解决数据竞争问题，人们提出了临界区模型，将所有可能操作共享数据的代码进行互斥，从而避免数据竞争。
- 为了实现临界区模型，人们首先想到使用一个锁变量来表示临界区是否可入。然而锁变量本身也是共享数据，针对锁变量本身出现的数据竞争导致它不能正常工作。
- 为了解决锁变量自身的数据竞争问题，硬件体系结构引入了特殊的`TSL`原子指令，允许对锁变量进行原子的读+写的操作，解决了锁变量本身的同步问题。
- 锁变量+`TSL`就是最基本的自旋锁。为了提高效率，人们要求锁持有期间不允许发生抢占，以尽快结束执行；此外，为了防止中断处理程序抢占同一个锁，还可以在锁争用成功后关闭本地中断。（当然，这两者的关系也许可以反过来说，比如本博客的正文中就是反过来讲的）
- 单核系统中，自旋锁的争用函数只需要关抢占（可能还要关中断），连锁变量都不需要。
- 我们学习了Linux的自旋锁实现代码，实际的代码与我们的简陋的伪代码还是有些不同之处的。

自旋锁确实在一定程度上解决了数据竞争这一个同步问题，
并且自旋锁也确实成为了现在Linux等操作系统内核编程中最常用的同步手段。
但是自旋锁并不是完美的，还有一些问题它并没有解决，比如：
- 如果临界区代码需要执行阻塞操作（比如磁盘IO），显然使用自旋锁会导致错误，那应该如何处理？
- 如果临界区代码需要很长时间，比如在两块内存区域之间拷贝大量的数据（调用`memcpy`），如果才用自旋锁，其他进程可能需要等很长时间才能争用到这个锁。更糟的是，这些进程只能“盲等”在原地，不能做其他任何事情，这无疑是对CPU的巨大浪费。

这些问题，可以由操作系统介入，在调度系统的配合下，通过信号量、管程等同步手段和解决，我们将在下一篇博客中详细介绍。

最后，不妨留一个思考题给读者：在多核版本的自旋锁版本中，在自旋锁上锁入口处，为什么要先关抢占再尝试争用锁，而不是争用锁再关抢占？
